{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfYbHgghOW5g"
      },
      "source": [
        "# Importação das bibliotecas básicas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0p3DGaJUAAJu"
      },
      "outputs": [],
      "source": [
        "!pip -q install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J014K7ZNAAJv"
      },
      "outputs": [],
      "source": [
        "!pip -q install yellowbrick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewJ6gYx3AAJv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe084c7-2265-46b1-e4ba-c4db0db202bb",
        "id": "jr6zHny_AAJw"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzQjXv11xXiV"
      },
      "source": [
        "# Avaliação dos algoritmos\n",
        "\n",
        "Abaixom, segue uma lista especificando cada algoritmo de classificação para as mesmas basse de dados que fui usando para estudar e colocando cada um em um repositório distinto.\n",
        "[Link para o repositório](https://github.com/GaybsGimenez?tab=repositories)\n",
        "\n",
        "## Resultado de cada modelo testado utilizando o método tradicional de divisão em grupo de treinamento e teste.\n",
        "\n",
        "- Naïve Bayes: 93.80\n",
        "- Árvore de decisão: 98.20\n",
        "- Random forest: 98.40\n",
        "- Regras: 97.40\n",
        "- Knn: 98.60\n",
        "- Regressão logística: 94.60\n",
        "- SVM: 98.80\n",
        "- Redes neurais: 99.60\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ7xQAHIxbYS"
      },
      "source": [
        "## Tuning dos parâmetros com GridSearch\n",
        "O Tuning dos parâmetros no método de validação cruzada dos dados refere-se ao processo de ajustar e otimizar os parâmetros de um modelo de aprendizado de máquina para melhorar seu desempenho. A validação cruzada é uma técnica que envolve dividir os dados em múltiplas partes, treinando e testando o modelo várias vezes com diferentes subdivisões dos dados. O tuning dos parâmetros busca encontrar a combinação ideal de valores de parâmetros que maximize a precisão do modelo ao ser avaliado em várias partições dos dados, garantindo que o modelo seja robusto e generalize bem para dados novos e não vistos.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccUPFWrYxemd"
      },
      "source": [
        "### Preparação dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MylAn7hn1FNf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV # pesquisa em grade que escolhe o melhor conjunto de parametros, validação cruzada\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDT6WDGD1pDH"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/ML e Data Sciece com python/dataset/credit_risc/credit.pkl', 'rb') as f:\n",
        "  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Os dados estavam divididos em Treinamento e Teste.\n",
        "2. Para o trabalho utilizando o método de validação cruzada precisamos concatêna-los novamente\n",
        "3. Testar o método de validação cruzada com os algoritmos utilizados para estudo e suas respectivas acurácias:\n",
        "\n",
        "- Naïve Bayes: 93.80\n",
        "- Árvore de decisão: 98.20\n",
        "- Random forest: 98.40\n",
        "- Regras: 97.40\n",
        "- Knn: 98.60\n",
        "- Regressão logística: 94.60\n",
        "- SVM: 98.80\n",
        "- Redes neurais: 99.60\n"
      ],
      "metadata": {
        "id": "Rh8t53ahBfsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## concatenar essas duas bases, de treinamento e teste para ter a base completa novamente"
      ],
      "metadata": {
        "id": "V_VEw-Fl2GuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como esses dados ja estavam dividos em treinamento e teste, precisaremos concatená-los para termos a base completa novamente\n",
        "\n",
        "Não é necessário realizar a divisão dos dados em conjuntos de treinamento e teste, pois o algoritmo GridSearchCV executa a validação cruzada, automaticamente dividindo os dados em K partes para avaliação.\n"
      ],
      "metadata": {
        "id": "50sjLrVV1nEt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-CIO79O11M5",
        "outputId": "26147abd-a1d6-40e6-c9b5-8d2aff0d5730"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1500, 3), (1500,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Treinamento 1500 registros e 3 colunas (atributos previsores)\n",
        "X_credit_treinamento.shape, y_credit_treinamento.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwkW7PJj18Fs",
        "outputId": "fe03f02a-7947-4a54-d0e3-7135ea7b9160"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((500, 3), (500,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Teste\n",
        "X_credit_teste.shape, y_credit_teste.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sVj51hj2Gex",
        "outputId": "dcd25b38-75df-4f8e-d073-5b17f0e2b3c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# concatenação das bases de treinamento e teste\n",
        "X_credit = np.concatenate((X_credit_treinamento, X_credit_teste), axis = 0) # axis = 0, ele concatena as linhas / axis = 1 concatena as colunas\n",
        "X_credit.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-_tknm82UPP",
        "outputId": "bad9bc16-3d44-45ba-d737-34ad85e35357"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.3754462 ,  0.50631087,  0.10980934],\n",
              "       [ 1.45826409, -1.6489393 , -1.21501497],\n",
              "       [-0.79356829,  0.22531191, -0.43370226],\n",
              "       ...,\n",
              "       [ 1.37445674, -1.05746281, -1.12564819],\n",
              "       [-1.57087737, -0.63488173, -0.36981671],\n",
              "       [-1.03572293, -0.93978122,  0.04244312]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_credit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxh_pqJT2YQR",
        "outputId": "fcc4a658-808e-4223-d292-be910098eb04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000,)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# concatenar as respostas esperadas\n",
        "\n",
        "y_credit = np.concatenate((y_credit_treinamento, y_credit_teste), axis = 0)\n",
        "y_credit.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4lE4MbE2geE",
        "outputId": "20e4c36e-4657-499a-c48d-d58a2c19f409"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# 0 quando o cliente paga o emprestimo\n",
        "# 1 quando o clinete não paga o emprestimo\n",
        "y_credit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEC2nX_Bxgxb"
      },
      "source": [
        "### Árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0UqqFoY4Yh9"
      },
      "outputs": [],
      "source": [
        "parametros = {'criterion': ['gini', 'entropy'], # testar todos os parâmetros\n",
        "              'splitter': ['best', 'random'],\n",
        "              'min_samples_split': [2, 5, 10], # escolha dos valores de forma aleatória\n",
        "              'min_samples_leaf': [1, 5, 10]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guqdajYG35W_",
        "outputId": "6cae7643-14f2-4e32-9743-33af16867708"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
            "0.983\n"
          ]
        }
      ],
      "source": [
        "grid_search = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=parametros) # param_grid=parametros, assim recebe o dicionariod e parametros e compara todos com todos, setando um por um\n",
        "grid_search.fit(X_credit, y_credit) # passamos as respostas esperadas e previsores e  #fit. treinamento e ajuste dos parametro\n",
        "melhores_parametros = grid_search.best_params_ # criação da varição melhores_parametros\n",
        "melhor_resultado = grid_search.best_score_ # melhor accuracy\n",
        "print(melhores_parametros)\n",
        "print(melhor_resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparação Arvore de Decisão\n",
        "\n",
        "Com algoritmo de validação cruzada a acurácia teve melhora de 0.10\n",
        "\n",
        "* Árvore de decisão (divisão e teste): 98.20\n",
        "* Árvore de decisão (validação cruzada): 98.30\n",
        "\n",
        "Por meio do Tuning, os valores dos parametros reavaliados foram alterados para obtenção de melhores resultados:\n",
        "\n",
        "Antes, utilizamos valores padrões\n",
        "```\n",
        "{'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 5, 'splitter': 'best'}\n",
        "```"
      ],
      "metadata": {
        "id": "4EQ70O2i4grw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDFqhYqqxi0a"
      },
      "source": [
        "### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idYueU9xAF9F"
      },
      "outputs": [],
      "source": [
        "parametros = {'criterion': ['gini', 'entropy'],\n",
        "              'n_estimators': [10, 40, 100, 150], # numero de árvores\n",
        "              'min_samples_split': [2, 5, 10], # escolha dos valores de forma aleatória\n",
        "              'min_samples_leaf': [1, 5, 10]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yIa1BHx_7nm",
        "outputId": "9e14c02a-cfb2-4ed0-e0c0-8b38312d4ef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "0.9884999999999999\n"
          ]
        }
      ],
      "source": [
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parametros)\n",
        "grid_search.fit(X_credit, y_credit)\n",
        "melhores_parametros = grid_search.best_params_\n",
        "melhor_resultado = grid_search.best_score_\n",
        "print(melhores_parametros)\n",
        "print(melhor_resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparação RamdonForest\n",
        "\n",
        "Com algoritmo de validação cruzada a acurácia teve melhora de 0.44\n",
        "\n",
        "* RamdonForest (divisão e teste): 98.40%\n",
        "* RamdonForest (validação cruzada): 98.84%\n",
        "\n",
        "Por meio do Tuning, os valores dos parametros reavaliados foram alterados para obtenção de melhores resultados:\n",
        "\n",
        "Antes, utilizamos valores padrões\n",
        "```\n",
        "{'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
        "```"
      ],
      "metadata": {
        "id": "pyVLdJKp58Jf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2ukErzdxkYV"
      },
      "source": [
        "### Knn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1gIzTTWBQsW"
      },
      "outputs": [],
      "source": [
        "parametros = {'n_neighbors': [3, 5, 10, 20], # numero de vizinho mais próximos\n",
        "              'p': [1, 2]} # 2 = Distancia euclidiana e 1 = Distancia manhattan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVetFmg-BGe9",
        "outputId": "4b456116-36ac-4f97-d3c5-8275f917549b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_neighbors': 20, 'p': 1}\n",
            "0.9800000000000001\n"
          ]
        }
      ],
      "source": [
        "grid_search = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=parametros)\n",
        "grid_search.fit(X_credit, y_credit)\n",
        "melhores_parametros = grid_search.best_params_\n",
        "melhor_resultado = grid_search.best_score_\n",
        "print(melhores_parametros)\n",
        "print(melhor_resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparação NKK\n",
        "\n",
        "Com algoritmo de validação cruzada a acurácia teve redução de 0.60\n",
        "\n",
        "* knn (divisão e teste): 98.60%\n",
        "* knn (validação cruzada): 98.00%\n",
        "\n",
        "Por meio do Tuning, os valores dos parametros reavaliados foram alterados para obtenção de melhores resultados:\n",
        "\n",
        "Antes, utilizamos valores padrões agora, temos:\n",
        "\n",
        "```\n",
        "{'n_neighbors': 20, 'p': 1}\n",
        "```"
      ],
      "metadata": {
        "id": "uBf7t4Ue6sAA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg1nw3UtxleM"
      },
      "source": [
        "### Regressão logística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0ob3vpVCOM1"
      },
      "outputs": [],
      "source": [
        "parametros = {'tol': [0.0001, 0.00001, 0.000001], # valores de tolerância\n",
        "              'C': [1.0, 1.5, 2.0], # quanto maior o valor mais o algoritmo tentará se ancaixar nos dados\n",
        "              'solver': ['lbfgs', 'sag', 'saga']} # algoritmo utilizado para fazer o ajuste dos valores (encontrar os coeficientes) os outros parametros são: newton-cg liblinear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnnVFidNB3Jo",
        "outputId": "13859ab9-e600-4213-d683-e9fe909e8187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 1.0, 'solver': 'lbfgs', 'tol': 0.0001}\n",
            "0.9484999999999999\n"
          ]
        }
      ],
      "source": [
        "grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=parametros)\n",
        "grid_search.fit(X_credit, y_credit)\n",
        "melhores_parametros = grid_search.best_params_\n",
        "melhor_resultado = grid_search.best_score_\n",
        "print(melhores_parametros)\n",
        "print(melhor_resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparação Regressão logistica\n",
        "\n",
        "Com algoritmo de validação cruzada a acurácia teve melhora de 0.15\n",
        "\n",
        "* Regressão logistica (divisão e teste): 94.60%\n",
        "* Regressão logistica (validação cruzada): 94.85%\n",
        "\n",
        "Por meio do Tuning, os valores dos parametros reavaliados foram alterados para obtenção de melhores resultados:\n",
        "\n",
        "Antes, utilizamos valores padrões agora, temos:\n",
        "\n",
        "```\n",
        "{'C': 1.0, 'solver': 'lbfgs', 'tol': 0.0001}\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "s8JvpbXn8QR-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y25eVjAqCtUh"
      },
      "source": [
        "### SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0jMbKs8C0ol"
      },
      "outputs": [],
      "source": [
        "parametros = {'tol': [0.001, 0.0001, 0.00001], # valores de tolerancia\n",
        "              'C': [1.0, 1.5, 2.0], # quanto maior o valor, mais a tendencia do algoritmo de adaptar\n",
        "              'kernel': ['rbf', 'linear', 'poly', 'sigmoid']} #algoritmo utilizado para fazer o ajuste dos valores (encontrar os coeficientes) os outros parametros são: newton-cg liblinear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RArcu8ORCvCW",
        "outputId": "8520e8e6-2291-47ca-d8cb-610c7729af18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 1.5, 'kernel': 'rbf', 'tol': 0.001}\n",
            "0.9829999999999999\n"
          ]
        }
      ],
      "source": [
        "grid_search = GridSearchCV(estimator=SVC(), param_grid=parametros)\n",
        "grid_search.fit(X_credit, y_credit)\n",
        "melhores_parametros = grid_search.best_params_\n",
        "melhor_resultado = grid_search.best_score_\n",
        "print(melhores_parametros)\n",
        "print(melhor_resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparação SVM\n",
        "\n",
        "Com algoritmo de validação cruzada a acurácia teve redução de 0.50\n",
        "\n",
        "* SVM (divisão e teste): 98.80%\n",
        "* SVM (validação cruzada): 98.30%\n",
        "\n",
        "Por meio do Tuning, os valores dos parametros reavaliados foram alterados para obtenção de melhores resultados:\n",
        "\n",
        "Antes, utilizamos valores padrões agora, temos:\n",
        "\n",
        "```\n",
        "{'C': 1.5, 'kernel': 'rbf', 'tol': 0.001}\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "RPrYDref9Sw7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQZ2TUjHxn3V"
      },
      "source": [
        "### Redes neurais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqUo4Rx3DgeR"
      },
      "outputs": [],
      "source": [
        "parametros = {'activation': ['relu', 'logistic', 'tahn'], # funções de ativação (existem outros valores, mas vamos usar somente esses para não demorar muito)\n",
        "              'solver': ['adam', 'sgd'], # algoritmo utilizado para fazer o ajuste dos valores (encontrar os coeficientes) os outros parametros são: newton-cg liblinear\n",
        "              'batch_size': [10, 56]} # valor que indica de quantas em quantas vezes será feita a atualização dos pesos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwIabuVYDRNR",
        "outputId": "a00a0a3b-899f-48cd-fbd4-cc0833f85f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "20 fits failed out of a total of 60.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "20 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\", line 747, in fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 600, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'tanh', 'logistic', 'identity', 'relu'}. Got 'tahn' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.9965 0.9945 0.9965 0.973  0.995  0.948  0.9605 0.926     nan    nan\n",
            "    nan    nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "grid_search = GridSearchCV(estimator=MLPClassifier(), param_grid=parametros)\n",
        "grid_search.fit(X_credit, y_credit)\n",
        "melhores_parametros = grid_search.best_params_\n",
        "melhor_resultado = grid_search.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIHD2j_6EraC",
        "outputId": "472c8b5e-6338-41cd-9be9-dd0eacd4e2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'activation': 'relu', 'batch_size': 10, 'solver': 'adam'}\n",
            "0.9964999999999999\n"
          ]
        }
      ],
      "source": [
        "print(melhores_parametros)\n",
        "print(melhor_resultado)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comparação Rede Neural\n",
        "\n",
        "Com algoritmo de validação cruzada a acurácia teve redução de 0.50\n",
        "\n",
        "* Rede Neural (divisão e teste): 99.60%\n",
        "* Rede Neural (validação cruzada): 99.65%\n",
        "\n",
        "Por meio do Tuning, os valores dos parametros reavaliados foram alterados para obtenção de melhores resultados:\n",
        "\n",
        "Antes, utilizamos valores padrões agora, temos:\n",
        "\n",
        "```\n",
        "{'activation': 'relu', 'batch_size': 10, 'solver': 'adam'}\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "DiLzw11a_SHL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyRCfZ_fhLef"
      },
      "outputs": [],
      "source": [
        "!pip -q install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOUlbp8VUhTT"
      },
      "outputs": [],
      "source": [
        "!pip -q install yellowbrick"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVP1Ah9dhd1F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ikfKSdGINxr",
        "outputId": "dfe084c7-2265-46b1-e4ba-c4db0db202bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ]
}