# -*- coding: utf-8 -*-
"""SVM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MvjvPfg6UQva_a73UGmG51vFLJ_V3HVH
"""



"""# SVM

O algoritmo SVM (Support Vector Machine) é uma técnica de aprendizado de máquina usada para classificar dados em diferentes categorias. Ele cria uma linha (ou plano) que melhor divide os exemplos de diferentes classes, maximizando a distância entre eles. Isso ajuda a classificar novos dados com base nas características aprendidas durante o treinamento. O SVM é útil em muitas situações, especialmente quando os dados têm muitas características.

* Os kernels são fundamentais em algoritmos de máquinas de vetor de suporte (SVM) pois permitem transformar problemas não lineares em problemas lineares, tornando-os mais facilmente separáveis. Essas funções realizam mapeamentos de dados para espaços de características de dimensões mais altas, onde os dados possam ser linearmente separáveis.

* O parâmetro C no SVM indica o quanto devemos penalizar os erros de classificação. Se escolhemos um valor alto de C, o modelo SVM tentará classificar cada exemplo de treinamento corretamente, o que pode levar a um ajuste mais apertado aos dados. Por outro lado, valores baixos de C permitem mais erros de classificação, resultando em uma margem de separação mais ampla
    * Cuidado, pois valores muito elevados podem causar overfiting

É crucial testar diferentes kernels, como:

* o RBF (Radial Basis Function),
* linear,
* polinomial,
* Gaussiano


entre outros, e explorar diferentes valores para o parâmetro C durante o processo de ajuste do modelo. A seleção adequada dos kernels e valores de C pode resultar em melhorias significativas no desempenho do modelo SVM, aumentando sua capacidade de generalização e precisão na classificação de dado
"""

from sklearn.svm import SVC

"""## Base credit data - 98.80%"""

# carregar base de dados de credito
with open('/content/drive/MyDrive/ML e Data Sciece com python/dataset/credit_risc/credit.pkl', 'rb') as f:
  X_credit_treinamento, y_credit_treinamento, X_credit_teste, y_credit_teste = pickle.load(f)

# checar quantidade de registro
X_credit_treinamento.shape, y_credit_treinamento.shape

# observar a quantidade de registro na base de teste
X_credit_teste.shape, y_credit_teste.shape

"""### Importante:

* Instanciação do modelo SVM para classificação com o kernel RBF.
* O kernel 'rbf' é útil para mapear dados não linearmente separáveis em um espaço dimensional superior.
### Parâmetros:
* kernel: define o tipo de kernel a ser utilizado, neste caso, o RBF (Função de Base Radial).
* random_state: semente aleatória para garantir reprodutibilidade dos resultados.
* C: parâmetro de regularização. Controla o trade-off entre a maximização da margem e a minimização do erro de classificação.
* Quanto maior o valor de C, mais o modelo tentará classificar corretamente todos os pontos de treinamento.
    * CUIDADO, pois isso que pode levar a um ajuste excessivo (overfitting).
* C é definido como 2.0. Se desejar aumentar a penalidade por erros de classificação, pode-se tentar aumentar esse valor para 4.




"""

# cria um objeto do tipo SVC (Support Vector Classifier), que será utilizado para realizar a classificação.
svm_credit = SVC(kernel='rbf', random_state=1, C = 2.0) # 2 -> 4

# Faz o treinamento do modelo SVC utilizando os conjuntos de dados de treinamento X_credit_treinamento e y_credit_treinamento.
svm_credit.fit(X_credit_treinamento, y_credit_treinamento)

"""### Realizando previsões utilizando o modelo SVM treinado

* Utilizando o método predict() do objeto svm_credit para fazer previsões nos dados de teste X_credit_teste.
* Este método irá classificar os exemplos de teste com base no modelo SVM treinado.


"""

# Armazenando as previsões resultantes em uma variável chamada 'previsoes'
previsoes = svm_credit.predict(X_credit_teste)
previsoes

# Vizualização dos rótulos reais em uma variável chamada 'y_credit_teste', que será usada para comparação com as previsões feitas pelo modelo SVM.

y_credit_teste

# importação da classes para analise e avaliação da acurácia das previsões do modelo SVM.
from sklearn.metrics import accuracy_score, classification_report

#  função accuracy_score() para calcular a acurácia das previsões em relação aos rótulos reais.
accuracy_score(y_credit_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(svm_credit)
cm.fit(X_credit_treinamento, y_credit_treinamento)
cm.score(X_credit_teste, y_credit_teste)

print(classification_report(y_credit_teste, previsoes))

"""1. **Precisão (Precision):**
   - Classe 0 (Aprovado): A precisão é de 99%, o que indica que a grande maioria dos exemplos classificados como "Aprovado" pelo modelo SVM são realmente "Aprovados".
   - Classe 1 (Reprovado): A precisão é de 97%, indicando que a maioria dos exemplos classificados como "Reprovado" pelo modelo SVM são realmente "Reprovados".

2. **Revocação (Recall):**
   - Classe 0 (Aprovado): A revocação é de 100%, o que significa que o modelo identificou corretamente todos os exemplos verdadeiramente "Aprovados".
   - Classe 1 (Reprovado): A revocação é de 94%, indicando que o modelo identificou corretamente a maioria dos exemplos verdadeiramente "Reprovados".

3. **F1-Score:**
   - O F1-Score é uma média harmônica entre precisão e revocação, fornecendo uma medida única do desempenho do modelo.
   - O F1-Score para a classe 0 (Aprovado) é de 0.99 e para a classe 1 (Reprovado) é de 0.95, indicando um bom equilíbrio entre precisão e revocação em ambas as classes.

4. **Acurácia (Accuracy):**
   - A acurácia global do modelo SVM é de 99%, o que significa que ele classificou corretamente 99% dos exemplos da base de teste.

5. **Suporte (Support):**
   - O suporte indica o número de exemplos verdadeiros para cada classe na base de teste.
   - Há 436 exemplos da classe 0 (Aprovado) e 64 exemplos da classe 1 (Reprovado) na base de teste.

Esses resultados sugerem que o modelo SVM obteve um desempenho geral excelente na classificação dos exemplos da base de crédito, com altos níveis de precisão, revocação e F1-Score em ambas as classes.

## Base census - 85.07%
"""

# carregar a base de dados
with open('/content/drive/MyDrive/ML e Data Sciece com python/dataset/census/census.pkl', 'rb') as f:
  X_census_treinamento, y_census_treinamento, X_census_teste, y_census_teste = pickle.load(f)

# vizualizar quantidade de dados de treinamento
X_census_treinamento.shape, y_census_treinamento.shape

# vizualizar quantidade de dados de teste
X_census_teste.shape, y_census_teste.shape

# criar objeto SVC (kernel=linear e random- nao alterar)
svm_census = SVC(kernel='linear', random_state=1)

# realizar o treinamento da base de treinamento
svm_census.fit(X_census_treinamento, y_census_treinamento)

# A variável 'previsoes' guarda os valores de previsão feitos pelo modelo SVM treinado usando a base de teste 'X_census_teste' vai ser0 utilizada para avaliar o desempenho do modelo em dados não vistos.
previsoes = svm_census.predict(X_census_teste)
previsoes

y_census_teste

from sklearn.metrics import accuracy_score, classification_report
accuracy_score(y_census_teste, previsoes)

from yellowbrick.classifier import ConfusionMatrix
cm = ConfusionMatrix(svm_census)
cm.fit(X_census_treinamento, y_census_treinamento)
cm.score(X_census_teste, y_census_teste)

print(classification_report(y_census_teste, previsoes))

"""- A precisão (precision) para a classe "<=50K" é de 0.87, o que significa que, das instâncias classificadas como pertencentes a essa classe, 87% realmente pertencem a ela.
- O recall para a classe "<=50K" é de 0.94, indicando que o modelo identificou corretamente 94% das instâncias que realmente pertencem a essa classe.
- O F1-score para a classe "<=50K" é de 0.90, uma medida combinada de precisão e recall que indica um bom equilíbrio entre os dois.
- Para a classe ">50K", a precisão é de 0.75, o que sugere que 75% das instâncias classificadas como pertencentes a essa classe realmente pertencem a ela.
- O recall para a classe ">50K" é de 0.58, indicando que o modelo identificou corretamente 58% das instâncias que realmente pertencem a essa classe.
- O F1-score para a classe ">50K" é de 0.66, mostrando um desempenho moderado na harmonização de precisão e recall para esta classe.
- A acurácia (accuracy) geral do modelo é de 0.85, o que indica a proporção de todas as previsões corretas.
- A média ponderada (weighted avg) da precisão, recall e F1-score considera o desequilíbrio de classes, sendo 0.84 para precisão, 0.85 para recall e 0.84 para F1-score.
- O macro avg fornece a média não ponderada dos resultados de precisão, recall e F1-score para todas as classes, sendo 0.81 para precisão, 0.76 para recall e 0.78 para F1-score. Isso é útil para avaliar o desempenho geral do modelo, independentemente do desequilíbrio de classes.
"""